{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following synthetic dataset for this experiment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = {\n",
    "    'X': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Y': [2.4, 4.5, 6.1, 8.0, 10.2, 12.5, 15.1, 18.0, 21.2, 24.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "1. Perform the necessary data preparation steps.\n",
    "2. Implement Linear Regression and Polynomial Regression models with \n",
    "degrees 2, 3, and 4 using a programming language of your choice. Train each \n",
    "model using the provided dataset. \n",
    "3. Evaluate the performance of each model on the testing dataset using Mean \n",
    "Squared Error (MSE) and R-squared. Provide a comparative analysis of the \n",
    "results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'X': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Y': [2.4, 4.5, 6.1, 8.0, 10.2, 12.5, 15.1, 18.0, 21.2, 24.5]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X     Y\n",
      "0   1   2.4\n",
      "1   2   4.5\n",
      "2   3   6.1\n",
      "3   4   8.0\n",
      "4   5  10.2\n",
      "5   6  12.5\n",
      "6   7  15.1\n",
      "7   8  18.0\n",
      "8   9  21.2\n",
      "9  10  24.5\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " X    0\n",
      "Y    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values:\\n\", missing_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Implement Linear Regression\u001b[39;00m\n\u001b[0;32m      2\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 3\u001b[0m linear_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX\u001b[49m, Y)\n\u001b[0;32m      4\u001b[0m linear_predictions \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m      5\u001b[0m linear_mse \u001b[38;5;241m=\u001b[39m mean_squared_error(Y, linear_predictions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Implement Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X, Y)\n",
    "linear_predictions = linear_model.predict(X)\n",
    "linear_mse = mean_squared_error(Y, linear_predictions)\n",
    "linear_r2 = r2_score(Y, linear_predictions)\n",
    "print(\"Linear Regression:\")\n",
    "print(\"MSE:\", linear_mse)\n",
    "print(\"R-squared:\", linear_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Regression (degree 2):\n",
      "MSE: 0.02028484848484841\n",
      "R-squared: 0.9995848245753585\n",
      "\n",
      "Polynomial Regression (degree 3):\n",
      "MSE: 0.0096550116550117\n",
      "R-squared: 0.999802388291597\n",
      "\n",
      "Polynomial Regression (degree 4):\n",
      "MSE: 0.003745920745920767\n",
      "R-squared: 0.9999233312372275\n"
     ]
    }
   ],
   "source": [
    "# Implement Polynomial Regression with degrees 2, 3, and 4\n",
    "for degree in [2, 3, 4]:\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly_features.fit_transform(X)\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X_poly, Y)\n",
    "    poly_predictions = poly_model.predict(X_poly)\n",
    "    poly_mse = mean_squared_error(Y, poly_predictions)\n",
    "    poly_r2 = r2_score(Y, poly_predictions)\n",
    "    print(f\"\\nPolynomial Regression (degree {degree}):\")\n",
    "    print(\"MSE:\", poly_mse)\n",
    "    print(\"R-squared:\", poly_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Polynomial Regression with degrees 2, 3, and 4\n",
    "for degree in [2, 3, 4]:\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly_features.fit_transform(X)\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X_poly, Y)\n",
    "    poly_predictions = poly_model.predict(X_poly)\n",
    "    poly_mse = mean_squared_error(Y, poly_predictions)\n",
    "    poly_r2 = r2_score(Y, poly_predictions)\n",
    "    print(f\"\\nPolynomial Regression (degree {degree}):\")\n",
    "    print(\"MSE:\", poly_mse)\n",
    "    print(\"R-squared:\", poly_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Testing:\n",
      "MSE: 0.372435629017448\n",
      "R-squared: 0.9946583150486937\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Linear Regression on the testing dataset\n",
    "linear_predictions_test = linear_model.predict(X_test)\n",
    "linear_mse_test = mean_squared_error(Y_test, linear_predictions_test)\n",
    "linear_r2_test = r2_score(Y_test, linear_predictions_test)\n",
    "print(\"Linear Regression - Testing:\")\n",
    "print(\"MSE:\", linear_mse_test)\n",
    "print(\"R-squared:\", linear_r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Regression (degree 2) - Testing:\n",
      "MSE: 0.03661319260065262\n",
      "R-squared: 0.999474872636514\n",
      "\n",
      "Polynomial Regression (degree 3) - Testing:\n",
      "MSE: 0.03661319260065262\n",
      "R-squared: 0.999474872636514\n",
      "\n",
      "Polynomial Regression (degree 4) - Testing:\n",
      "MSE: 0.03661319260065262\n",
      "R-squared: 0.999474872636514\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Polynomial Regression models on the testing dataset\n",
    "for degree in [2, 3, 4]:\n",
    "    poly_features_test = PolynomialFeatures(degree=degree)\n",
    "    X_poly_train = poly_features.fit_transform(X_train)\n",
    "    X_poly_test = poly_features.transform(X_test)\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X_poly_train, Y_train)\n",
    "    poly_predictions_test = poly_model.predict(X_poly_test)\n",
    "    poly_mse_test = mean_squared_error(Y_test, poly_predictions_test)\n",
    "    poly_r2_test = r2_score(Y_test, poly_predictions_test)\n",
    "    print(f\"\\nPolynomial Regression (degree {degree}) - Testing:\")\n",
    "    print(\"MSE:\", poly_mse_test)\n",
    "    print(\"R-squared:\", poly_r2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Information:\n",
    "\n",
    "a. Briefly describe the \"Breast Cancer\" dataset.\n",
    "\n",
    "b. Justify the selection of this dataset for studying the comparative performance of\n",
    "Logistic and Polynomial Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('breast-cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variable\n",
    "X = data.drop('diagnosis', axis=1)\n",
    "y = data['diagnosis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "acc_log_reg = accuracy_score(y_test, y_pred_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Polynomial Regression (degree=2): 0.9736842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Polynomial Regression (degree=3): 0.9649122807017544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Polynomial Regression (degree=4): 0.9385964912280702\n",
      "Accuracy for Logistic Regression: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Polynomial Regression\n",
    "degrees = [2, 3, 4]\n",
    "for degree in degrees:\n",
    "    poly_reg = make_pipeline(PolynomialFeatures(degree=degree), StandardScaler(), LogisticRegression())\n",
    "    poly_reg.fit(X_train, y_train)\n",
    "    y_pred_poly_reg = poly_reg.predict(X_test)\n",
    "    acc_poly_reg = accuracy_score(y_test, y_pred_poly_reg)\n",
    "    print(f\"Accuracy for Polynomial Regression (degree={degree}): {acc_poly_reg}\")\n",
    "\n",
    "print(f\"Accuracy for Logistic Regression: {acc_log_reg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Implementation:\n",
    "\n",
    "a. Implement a Logistic Regression model and Polynomial Regression models with\n",
    "degrees 2, 3, and 4 using a programming language of your choice.\n",
    "\n",
    "b. Clearly present the code and any relevant parameters used in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('breast-cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variable\n",
    "X = data.drop('diagnosis', axis=1)\n",
    "y = data['diagnosis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression (degree=2):\n",
      "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
      "                ('logisticregression', LogisticRegression())])\n",
      "\n",
      "\n",
      "Polynomial Regression (degree=3):\n",
      "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures(degree=3)),\n",
      "                ('logisticregression', LogisticRegression())])\n",
      "\n",
      "\n",
      "Polynomial Regression (degree=4):\n",
      "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures(degree=4)),\n",
      "                ('logisticregression', LogisticRegression())])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement Polynomial Regression with degrees 2, 3, and 4\n",
    "degrees = [2, 3, 4]\n",
    "for degree in degrees:\n",
    "    poly_reg = make_pipeline(PolynomialFeatures(degree=degree), LogisticRegression())\n",
    "    poly_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Print the model and its parameters\n",
    "    print(f\"Polynomial Regression (degree={degree}):\")\n",
    "    print(poly_reg)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "# Print Logistic Regression model and its parameters\n",
    "print(\"Logistic Regression:\")\n",
    "print(log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Evaluation:\n",
    "\n",
    "a. Evaluate the performance of each model on the \"Breast Cancer\" dataset using binary\n",
    "classification metrics: accuracy, precision, recall, and F1-score.\n",
    "\n",
    "b. Compare and analyze the performance metrics obtained from Logistic Regression\n",
    "and Polynomial Regression models with different degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate Logistic Regression\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "precision_log_reg = precision_score(y_test, y_pred_log_reg, pos_label='M')\n",
    "recall_log_reg = recall_score(y_test, y_pred_log_reg, pos_label='M')\n",
    "f1_log_reg = f1_score(y_test, y_pred_log_reg, pos_label='M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.6228070175438597\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_log_reg}\")\n",
    "print(f\"Precision: {precision_log_reg}\")\n",
    "print(f\"Recall: {recall_log_reg}\")\n",
    "print(f\"F1-score: {f1_log_reg}\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression (degree=2) Metrics:\n",
      "Accuracy: 0.37719298245614036\n",
      "Precision: 0.37719298245614036\n",
      "Recall: 1.0\n",
      "F1-score: 0.5477707006369427\n",
      "\n",
      "\n",
      "Polynomial Regression (degree=3) Metrics:\n",
      "Accuracy: 0.37719298245614036\n",
      "Precision: 0.37719298245614036\n",
      "Recall: 1.0\n",
      "F1-score: 0.5477707006369427\n",
      "\n",
      "\n",
      "Polynomial Regression (degree=4) Metrics:\n",
      "Accuracy: 0.37719298245614036\n",
      "Precision: 0.37719298245614036\n",
      "Recall: 1.0\n",
      "F1-score: 0.5477707006369427\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Polynomial Regression models with degrees 2, 3, and 4\n",
    "for degree in degrees:\n",
    "    y_pred_poly_reg = poly_reg.predict(X_test)\n",
    "    accuracy_poly_reg = accuracy_score(y_test, y_pred_poly_reg)\n",
    "    precision_poly_reg = precision_score(y_test, y_pred_poly_reg, pos_label='M')\n",
    "    recall_poly_reg = recall_score(y_test, y_pred_poly_reg, pos_label='M')\n",
    "    f1_poly_reg = f1_score(y_test, y_pred_poly_reg, pos_label='M')\n",
    "    \n",
    "    # Print metrics for Polynomial Regression\n",
    "    print(f\"Polynomial Regression (degree={degree}) Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy_poly_reg}\")\n",
    "    print(f\"Precision: {precision_poly_reg}\")\n",
    "    print(f\"Recall: {recall_poly_reg}\")\n",
    "    print(f\"F1-score: {f1_poly_reg}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
