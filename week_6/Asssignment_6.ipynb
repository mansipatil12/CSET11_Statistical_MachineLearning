{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load dataset into Pandas Data Frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bank_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Display the entries in data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.021</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>success</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.729</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.869</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>59</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.866</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>31</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.860</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>42</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>48</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>92.431</td>\n",
       "      <td>-26.9</td>\n",
       "      <td>0.742</td>\n",
       "      <td>5017.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>25</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.859</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job  marital            education  default housing loan  \\\n",
       "0       44  blue-collar  married             basic.4y  unknown     yes   no   \n",
       "1       53   technician  married              unknown       no      no   no   \n",
       "2       28   management   single    university.degree       no     yes   no   \n",
       "3       39     services  married          high.school       no      no   no   \n",
       "4       55      retired  married             basic.4y       no     yes   no   \n",
       "...    ...          ...      ...                  ...      ...     ...  ...   \n",
       "41183   59      retired  married          high.school  unknown      no  yes   \n",
       "41184   31    housemaid  married             basic.4y  unknown      no   no   \n",
       "41185   42       admin.   single    university.degree  unknown     yes  yes   \n",
       "41186   48   technician  married  professional.course       no      no  yes   \n",
       "41187   25      student   single          high.school       no      no   no   \n",
       "\n",
       "         contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "0       cellular   aug         thu  ...         1    999         0   \n",
       "1       cellular   nov         fri  ...         1    999         0   \n",
       "2       cellular   jun         thu  ...         3      6         2   \n",
       "3       cellular   apr         fri  ...         2    999         0   \n",
       "4       cellular   aug         fri  ...         1      3         1   \n",
       "...          ...   ...         ...  ...       ...    ...       ...   \n",
       "41183  telephone   jun         thu  ...         1    999         0   \n",
       "41184  telephone   may         thu  ...         2    999         0   \n",
       "41185  telephone   may         wed  ...         3    999         0   \n",
       "41186  telephone   oct         tue  ...         2    999         0   \n",
       "41187  telephone   may         fri  ...         4    999         0   \n",
       "\n",
       "          poutcome emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  \\\n",
       "0      nonexistent          1.4          93.444          -36.1      4.963   \n",
       "1      nonexistent         -0.1          93.200          -42.0      4.021   \n",
       "2          success         -1.7          94.055          -39.8      0.729   \n",
       "3      nonexistent         -1.8          93.075          -47.1      1.405   \n",
       "4          success         -2.9          92.201          -31.4      0.869   \n",
       "...            ...          ...             ...            ...        ...   \n",
       "41183  nonexistent          1.4          94.465          -41.8      4.866   \n",
       "41184  nonexistent          1.1          93.994          -36.4      4.860   \n",
       "41185  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "41186  nonexistent         -3.4          92.431          -26.9      0.742   \n",
       "41187  nonexistent          1.1          93.994          -36.4      4.859   \n",
       "\n",
       "       nr_employed  y  \n",
       "0           5228.1  0  \n",
       "1           5195.8  0  \n",
       "2           4991.6  1  \n",
       "3           5099.1  0  \n",
       "4           5076.2  1  \n",
       "...            ... ..  \n",
       "41183       5228.1  0  \n",
       "41184       5191.0  0  \n",
       "41185       5191.0  0  \n",
       "41186       5017.5  0  \n",
       "41187       5191.0  0  \n",
       "\n",
       "[41188 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (41188, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Fetch the column name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
      "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx',\n",
      "       'cons_conf_idx', 'euribor3m', 'nr_employed', 'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Column names:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Check whether data contains missing value or not. if require, pre-process the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp_var_rate      0\n",
      "cons_price_idx    0\n",
      "cons_conf_idx     0\n",
      "euribor3m         0\n",
      "nr_employed       0\n",
      "y                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values:\", df.isnull().sum())\n",
    "\n",
    "data = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Split the dataset into train and test in the following ratio (Hint: Use train_test_split class) (10)\n",
    "   a) 70:30\n",
    "   b) 80:20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test in the ratio 1) 70:30 and 2) 80:20\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train70, test70 = train_test_split(data, test_size=0.3, random_state=0)\n",
    "\n",
    "train80, test80 = train_test_split(data, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train70, X_test70, y_train70, y_test30 = train_test_split(\n",
    "    data.drop(\"y\", axis=1), data[\"y\"], test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_train80, X_test80, y_train80, y_test20 = train_test_split(\n",
    "    data.drop(\"y\", axis=1), data[\"y\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Create Logistic Regression Models on the splitting criterion as mentioned above (Hint: Use sklearn.linear_model.LogisticRegression class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 70:30\n",
    "\n",
    "logreg70 = LogisticRegression()\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "cat_vars = [\"job\", \"marital\", \"education\", \"contact\", \"poutcome\"]\n",
    "encoder = OneHotEncoder(categories=\"auto\", drop=\"first\")\n",
    "X_train70_encoded = encoder.fit_transform(X_train70[cat_vars])\n",
    "X_test70_encoded = encoder.transform(X_test70[cat_vars])\n",
    "\n",
    "# Combine the encoded categorical variables with the numerical variables\n",
    "num_vars = [\"age\", \"duration\", \"campaign\", \"pdays\", \"previous\"]\n",
    "X_train70_num = X_train70[num_vars]\n",
    "X_test70_num = X_test70[num_vars]\n",
    "X_train70_final = np.concatenate([X_train70_encoded.toarray(), X_train70_num], axis=1)\n",
    "X_test70_final = np.concatenate([X_test70_encoded.toarray(), X_test70_num], axis=1)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logreg70.fit(X_train70_final, y_train70)\n",
    "y_pred70 = logreg70.predict(X_test70_final)\n",
    "\n",
    "# 80:20\n",
    "\n",
    "logreg80 = LogisticRegression()\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "X_train80_encoded = encoder.fit_transform(X_train80[cat_vars])\n",
    "X_test80_encoded = encoder.transform(X_test80[cat_vars])\n",
    "\n",
    "# Combine the encoded categorical variables with the numerical variables\n",
    "X_train80_num = X_train80[num_vars]\n",
    "X_test80_num = X_test80[num_vars]\n",
    "X_train80_final = np.concatenate([X_train80_encoded.toarray(), X_train80_num], axis=1)\n",
    "X_test80_final = np.concatenate([X_test80_encoded.toarray(), X_test80_num], axis=1)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "y_train80 = train80[\"y\"]\n",
    "X_test80 = test80.drop(\"y\", axis=1)\n",
    "y_test80 = test80[\"y\"]\n",
    "logreg80.fit(X_train80_final, y_train80)\n",
    "y_pred80 = logreg80.predict(X_test80_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Find out the regression coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\CSET_211_LAB\\week_6\\Asssignment_6.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# fit the logistic regression model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m logreg \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m logreg\u001b[39m.\u001b[39;49mfit(X_train80_df, y_train80)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRegression coefficients for 80:20 split:\u001b[39m\u001b[39m\"\u001b[39m, logreg\u001b[39m.\u001b[39mcoef_)\n",
      "File \u001b[1;32mc:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1196\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1197\u001b[0m     X,\n\u001b[0;32m   1198\u001b[0m     y,\n\u001b[0;32m   1199\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1200\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1201\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1202\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1203\u001b[0m )\n\u001b[0;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# convert the sparse matrices to pandas DataFrames\n",
    "X_train70_encoded_df = pd.DataFrame(X_train70_encoded.toarray(), columns=encoder.get_feature_names_out(cat_vars))\n",
    "X_train80_encoded_df = pd.DataFrame(X_train80_encoded.toarray(), columns=encoder.get_feature_names_out(cat_vars))\n",
    "\n",
    "# concatenate the encoded categorical variables with the numerical variables\n",
    "X_train70_df = pd.concat([X_train70_encoded_df, X_train70[num_vars]], axis=1)\n",
    "X_train80_df = pd.concat([X_train80_encoded_df, X_train80[num_vars]], axis=1)\n",
    "\n",
    "# fit the logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train80_df, y_train80)\n",
    "print(\"Regression coefficients for 80:20 split:\", logreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write the equation of SLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equation of SLR for 70:30 split:\n",
      "y = -0.49961378809213597 * age + -0.11599658055961978 * job_blue-collar + -0.03527749092887187 * job_entrepreneur + -0.07812368288890306 * job_housemaid + 0.5356891023583932 * job_management + -0.11965116565184226 * job_retired + -0.2767214098898425 * job_self-employed + 0.41652842209300756 * job_services + -0.21076371069681082 * job_student + 0.04817758533424921 * job_technician + 0.006467020960267038 * job_unemployed + -0.09095237890184123 * marital_married + 0.14817270863078097 * marital_single + -0.009934535638084325 * education_secondary + -0.08805501654712974 * education_tertiary + -0.25270100165103904 * contact_telephone + -0.08098674788268818 * contact_unknown + 0.011011645930175942 * poutcome_other + -0.00710970612280844 * poutcome_success + -0.016904780974107324 * poutcome_unknown + 0.16221962801547407 * age + -1.126752545776159 * duration + -0.24096311706411003 * campaign + -0.15227506934050278 * pdays + 0.0021051027316631742 * previous\n"
     ]
    }
   ],
   "source": [
    "print(\"Equation of SLR for 70:30 split:\")\n",
    "print(\n",
    "    \"y =\",\n",
    "    logreg70.coef_[0][0],\n",
    "    \"* age +\",\n",
    "    logreg70.coef_[0][1],\n",
    "    \"* job_blue-collar +\",\n",
    "    logreg70.coef_[0][2],\n",
    "    \"* job_entrepreneur +\",\n",
    "    logreg70.coef_[0][3],\n",
    "    \"* job_housemaid +\",\n",
    "    logreg70.coef_[0][4],\n",
    "    \"* job_management +\",\n",
    "    logreg70.coef_[0][5],\n",
    "    \"* job_retired +\",\n",
    "    logreg70.coef_[0][6],\n",
    "    \"* job_self-employed +\",\n",
    "    logreg70.coef_[0][7],\n",
    "    \"* job_services +\",\n",
    "    logreg70.coef_[0][8],\n",
    "    \"* job_student +\",\n",
    "    logreg70.coef_[0][9],\n",
    "    \"* job_technician +\",\n",
    "    logreg70.coef_[0][10],\n",
    "    \"* job_unemployed +\",\n",
    "    logreg70.coef_[0][11],\n",
    "    \"* marital_married +\",\n",
    "    logreg70.coef_[0][12],\n",
    "    \"* marital_single +\",\n",
    "    logreg70.coef_[0][13],\n",
    "    \"* education_secondary +\",\n",
    "    logreg70.coef_[0][14],\n",
    "    \"* education_tertiary +\",\n",
    "    logreg70.coef_[0][15],\n",
    "    \"* contact_telephone +\",\n",
    "    logreg70.coef_[0][16],\n",
    "    \"* contact_unknown +\",\n",
    "    logreg70.coef_[0][17],\n",
    "    \"* poutcome_other +\",\n",
    "    logreg70.coef_[0][18],\n",
    "    \"* poutcome_success +\",\n",
    "    logreg70.coef_[0][19],\n",
    "    \"* poutcome_unknown +\",\n",
    "    logreg70.coef_[0][20],\n",
    "    \"* age +\",\n",
    "    logreg70.coef_[0][21],\n",
    "    \"* duration +\",\n",
    "    logreg70.coef_[0][22],\n",
    "    \"* campaign +\",\n",
    "    logreg70.coef_[0][23],\n",
    "    \"* pdays +\",\n",
    "    logreg70.coef_[0][24],\n",
    "    \"* previous\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Perform the prediction on the test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on test dataset for 70:30 split: [0 0 0 ... 0 0 0]\n",
      "Prediction on test dataset for 80:20 split: [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction on test dataset for 70:30 split:\", y_pred70)\n",
    "print(\"Prediction on test dataset for 80:20 split:\", y_pred80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Train the model against different Independent variable features vs Dependent variable (I.e., Single independent variable vs dependent variable) and Identify the most desirable feature for the dependent variable Y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for age: 0.88864611151574\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'technician'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\CSET_211_LAB\\week_6\\Asssignment_6.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m logreg \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m logreg\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m y_pred \u001b[39m=\u001b[39m logreg\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CSET_211_LAB/week_6/Asssignment_6.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1196\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1197\u001b[0m     X,\n\u001b[0;32m   1198\u001b[0m     y,\n\u001b[0;32m   1199\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1200\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1201\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1202\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1203\u001b[0m )\n\u001b[0;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mansi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'technician'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create a list of all columns except for the dependent variable Y\n",
    "independent_vars = [col for col in df.columns if col != \"y\"]\n",
    "\n",
    "# initialize variables to keep track of the best feature and its accuracy\n",
    "best_feature = \"\"\n",
    "best_accuracy = 0\n",
    "\n",
    "# iterate through each independent variable and train a logistic regression model\n",
    "for var in independent_vars:\n",
    "    X = df[var].values.reshape(-1, 1)\n",
    "    y = df[\"y\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=0\n",
    "    )\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy for {var}: {accuracy}\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_feature = var\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "# print the best feature and its accuracy\n",
    "print(f\"Best feature: {best_feature}\")\n",
    "print(f\"Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding of categorical variables(job','marital','education','contact','poutcome')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  default housing loan month day_of_week  duration  campaign  pdays  \\\n",
      "0   44  unknown     yes   no   aug         thu       210         1    999   \n",
      "1   53       no      no   no   nov         fri       138         1    999   \n",
      "2   28       no     yes   no   jun         thu       339         3      6   \n",
      "3   39       no      no   no   apr         fri       185         2    999   \n",
      "4   55       no     yes   no   aug         fri       137         1      3   \n",
      "\n",
      "   previous  ...  education_high.school  education_illiterate  \\\n",
      "0         0  ...                      0                     0   \n",
      "1         0  ...                      0                     0   \n",
      "2         2  ...                      0                     0   \n",
      "3         0  ...                      1                     0   \n",
      "4         1  ...                      0                     0   \n",
      "\n",
      "   education_professional.course  education_university.degree  \\\n",
      "0                              0                            0   \n",
      "1                              0                            0   \n",
      "2                              0                            1   \n",
      "3                              0                            0   \n",
      "4                              0                            0   \n",
      "\n",
      "   education_unknown  contact_cellular  contact_telephone  poutcome_failure  \\\n",
      "0                  0                 1                  0                 0   \n",
      "1                  1                 1                  0                 0   \n",
      "2                  0                 1                  0                 0   \n",
      "3                  0                 1                  0                 0   \n",
      "4                  0                 1                  0                 0   \n",
      "\n",
      "   poutcome_nonexistent  poutcome_success  \n",
      "0                     1                 0  \n",
      "1                     1                 0  \n",
      "2                     0                 1  \n",
      "3                     1                 0  \n",
      "4                     0                 1  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "cat_vars = [\"job\", \"marital\", \"education\", \"contact\", \"poutcome\"]\n",
    "\n",
    "# Perform one-hot encoding on the categorical variables\n",
    "data_encoded = pd.get_dummies(data, columns=cat_vars)\n",
    "\n",
    "# Print the first 5 rows of the encoded data\n",
    "print(data_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Binary Encoding of Binary o/p variables('default','housing','loan','y') with 1 and =0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          job  marital          education  default  housing  loan  \\\n",
      "0   44  blue-collar  married           basic.4y      NaN      1.0   0.0   \n",
      "1   53   technician  married            unknown      0.0      0.0   0.0   \n",
      "2   28   management   single  university.degree      0.0      1.0   0.0   \n",
      "3   39     services  married        high.school      0.0      0.0   0.0   \n",
      "4   55      retired  married           basic.4y      0.0      1.0   0.0   \n",
      "\n",
      "    contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
      "0  cellular   aug         thu  ...         1    999         0  nonexistent   \n",
      "1  cellular   nov         fri  ...         1    999         0  nonexistent   \n",
      "2  cellular   jun         thu  ...         3      6         2      success   \n",
      "3  cellular   apr         fri  ...         2    999         0  nonexistent   \n",
      "4  cellular   aug         fri  ...         1      3         1      success   \n",
      "\n",
      "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed   y  \n",
      "0          1.4          93.444          -36.1      4.963       5228.1 NaN  \n",
      "1         -0.1          93.200          -42.0      4.021       5195.8 NaN  \n",
      "2         -1.7          94.055          -39.8      0.729       4991.6 NaN  \n",
      "3         -1.8          93.075          -47.1      1.405       5099.1 NaN  \n",
      "4         -2.9          92.201          -31.4      0.869       5076.2 NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary to map the binary values to 1 and 0\n",
    "binary_map = {\"yes\": 1, \"no\": 0}\n",
    "\n",
    "# Apply the binary mapping to the binary output variables\n",
    "data[\"default\"] = data[\"default\"].map(binary_map)\n",
    "data[\"housing\"] = data[\"housing\"].map(binary_map)\n",
    "data[\"loan\"] = data[\"loan\"].map(binary_map)\n",
    "data[\"y\"] = data[\"y\"].map(binary_map)\n",
    "\n",
    "# Print the first 5 rows of the encoded data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find count of each month and Replace Encoding for month categorical varaibls(1,2,3.......12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          job  marital          education  default  housing  loan  \\\n",
      "0   44  blue-collar  married           basic.4y      NaN      1.0   0.0   \n",
      "1   53   technician  married            unknown      0.0      0.0   0.0   \n",
      "2   28   management   single  university.degree      0.0      1.0   0.0   \n",
      "3   39     services  married        high.school      0.0      0.0   0.0   \n",
      "4   55      retired  married           basic.4y      0.0      1.0   0.0   \n",
      "\n",
      "    contact  month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
      "0  cellular      8         thu  ...         1    999         0  nonexistent   \n",
      "1  cellular     11         fri  ...         1    999         0  nonexistent   \n",
      "2  cellular      6         thu  ...         3      6         2      success   \n",
      "3  cellular      4         fri  ...         2    999         0  nonexistent   \n",
      "4  cellular      8         fri  ...         1      3         1      success   \n",
      "\n",
      "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed   y  \n",
      "0          1.4          93.444          -36.1      4.963       5228.1 NaN  \n",
      "1         -0.1          93.200          -42.0      4.021       5195.8 NaN  \n",
      "2         -1.7          94.055          -39.8      0.729       4991.6 NaN  \n",
      "3         -1.8          93.075          -47.1      1.405       5099.1 NaN  \n",
      "4         -2.9          92.201          -31.4      0.869       5076.2 NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the count of each month\n",
    "data[\"month\"].value_counts()\n",
    "\n",
    "# Define a dictionary to map the months to numbers\n",
    "month_map = {\n",
    "    \"jan\": 1,\n",
    "    \"feb\": 2,\n",
    "    \"mar\": 3,\n",
    "    \"apr\": 4,\n",
    "    \"may\": 5,\n",
    "    \"jun\": 6,\n",
    "    \"jul\": 7,\n",
    "    \"aug\": 8,\n",
    "    \"sep\": 9,\n",
    "    \"oct\": 10,\n",
    "    \"nov\": 11,\n",
    "    \"dec\": 12,\n",
    "}\n",
    "\n",
    "# Apply the mapping to the month column\n",
    "data[\"month\"] = data[\"month\"].map(month_map)\n",
    "\n",
    "# Print the first 5 rows of the encoded data\n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
